install.packages("shiny")
install.packages("learnr")
# Working with 10X Visium Data
library(Seurat)
install.packages("Seurat")
install.packages("renv")
remove.packages("Seurat")
# Working with 10X Visium Data
library(Seurat)
cwd
getwd()
setwd("Documents/CS50R/")
ls
file.create("chicks.R")
read.csv("chicks.csv") # I don't have access to this file.
View(chicks)
chicks <- read.csv("chicks.csv") # I don't have access to this file.
View(chicks)
# How much do chicks weight across all different feeds?
mean(chicks$weight)
# If there are NA values, we need to make a decision about what to do them
# We should not ignore NA values
mean(chick$weight, na.rm = TRUE)
# If there are NA values, we need to make a decision about what to do them
# We should not ignore NA values
mean(chicks$weight, na.rm = TRUE)
?mean
# We can also index into chicks using a vector
casein_chicks <- chicks[c(1,2,3), ]
mean(casein_chicks$weight)
# we can be even more efficient and use logical expressions
chicks$feed == "casein"
# we can be even more efficient and use logical expressions
chicks$feed == "casein"
chicks[chicks$feed == "casein"]
chicks[, chicks$feed == "casein"]
chicks[chicks$feed == "casein",]
chicks[chicks$feed == "casein"]
# we can be even more efficient and use logical expressions
# We have a logical filter now
filter <- chicks$feed == "casein"
chicks[filter, ]
mean(casein_chicks$weight)
# Get mean weight of chicks on linseed
filter <- chicks$feed == "linseed"
linseed_chicks <- chicks[filter, ]
mean(casein_chicks$weight)
mean(linseed_chicks$weight)
mean(linseed_chicks$weight, na.rm = TRUE)
chicks$weight == NA
is.na(chicks$weight)
# Check which values are not NA
!is.na(chicks$weight)
# Get all rows of chicks where weight is not equal to NA
chicks <- chicks[!is.na(chicks$weight), ]
# Use function subset to get all chicks that ere on soybean diet
soybean_chicks <- subset(chicks, feed == "soybean")
soybean_chicks
# Reset the rownames for chicks dataframe
rownames(chicks) <- NULL
rownames(chicks)
chicks <- read.csv("chicks.csv")
# Use function subset to remove all rows where weight is NA
chicks <- subset(chicks, !is.na(weight))
# Use function subset to remove all rows where weight is NA
chicks <- subset(chicks, !is.na(weight))
rownames(chicks)
# Reset the rownames for chicks dataframe
rownames(chicks) <- NULL
rownames(chicks)
chicks <- read.csv("chicks.csv")
# Count the total number of NA's in the weight column
sum(is.na(chicks$weight))
file.create("feed.R")
chicks <- read.csv("chicks.csv")
# Remove NA values
chicks <- subset(chicks, !is.na(weights))
# Determine feed options
unique(chicks$feed)
# prompt user with options
cat("1.", feed_options[1])
# Determine feed options
feed_options <- unique(chicks$feed)
# prompt user with options
cat("1.", feed_options[1])
source("~/Documents/CS50R/feed.R")
View(chicks)
source("~/Documents/CS50R/feed.R")
[:6]
1:6
# prompt user with options
formatted_options <- paste0(1:6, ". ", feed_options)
formatted_options
# prompt user with options
num_options <- len(feed_options)
# prompt user with options
num_options <- length(feed_options)
source("~/Documents/CS50R/feed.R")
feed_type
feed_choice
# Get back the option that user entered
selected_feed = feed_options[feed_choice]
source("~/Documents/CS50R/feed.R")
file.create("sales.R")
getwd()
file.create("count_function.R")
source("~/Documents/CS50R/count_function.R")
file.create("duck.R")
ls()
rm(list=ls())
source("~/Documents/CS50R/duck.R")
1:10
[1:10]
source("~/Documents/CS50R/count_function.R")
file.create("tabulate.R")
votes <- read.csv("votes.csv")
View(votes)
?read.csv
View(votes)
votes <- read.csv("votes.csv", row.names = "candidate")
View(votes)
votes["mario",]
source("~/Documents/CS50R/tabulate.R")
total_votes
type(total_votes)
total_votes
source("~/Documents/CS50R/tabulate.R")
total_votes
apply(votes, MARGIN = 1, FUN = sum)
apply(votes, MARGIN = 2, FUN = sum)
# Margin = 2 apply funcion across rows
total_votes <- apply(votes, MARGIN = 2, FUN = sum)
# Sort the total_votes
sort(total_votes)
?sort
#Sort the total votes from high to low
sort(total_votes, decreasing = TRUE)
# Margin specifies whether to apply fun across rows or columns
# Margin = 1 apply funcion across rows
total_votes <- apply(votes, MARGIN = 1, FUN = sum)
# Sort the total_votes from low to high
sort(total_votes)
#Sort the total votes from high to low
sort(total_votes, decreasing = TRUE)
source("~/Documents/CS50R/tabulate.R")
install.packages("tidyverse")
library("tidyverse")
storms
file.create("storms.R")
library("tidyverse")
#look at the storms dataset that comes with dplyr
storms
# Remove columns from storms - use select function from dplyr
dplyr::select(
storms,
!c(lat, long, pressure, tropicalstorm_force_diameter, hurricane_force_diameter)
)
# instead of full column name, we can include additional functions
dplyr::select(
storms,
!c(lat, long, pressure, ends_with("diameter"))
)
dplyr::filter(
dplyr::select(
storms,
!c(lat, long, pressure, ends_with("diameter"))
),
status == "hurricane"
)
# Using pipe operators
storms |>
select(!c(lat, long, pressure, ends_with("diameter"))) |>
filter(status == "hurricane")
# sort data using arrange
storms |>
select(!c(lat, long, pressure, ends_with("diameter"))) |>
arrange(desc(wind))
# for rows with same wind speed, sort alphabetically by name
storms |>
select(!c(lat, long, pressure, ends_with("diameter"))) |>
arrange(desc(wind), name)
# Distinct function
# there are duplicate rows in the data.
# by default distinct() function looks at all the columns for a row and if all values are same, it would be considered duplicate.
# distinct will return only the first row out of all duplicates it found.
# We can also tell distinct which columns to look at to find duplicates.
storms |>
select(!c(lat, long, pressure, ends_with("diameter"))) |>
arrange(desc(wind), name) |>
distinct(name, year, .keep_all = TRUE)
# Distinct function
# there are duplicate rows in the data.
# by default distinct() function looks at all the columns for a row and if all values are same, it would be considered duplicate.
# distinct will return only the first row out of all duplicates it found.
# We can also tell distinct which columns to look at to find duplicates.
hurricanes <- storms |>
select(!c(lat, long, pressure, ends_with("diameter"))) |>
arrange(desc(wind), name) |>
distinct(name, year, .keep_all = TRUE)
hurricanes |>
selct(c(year, name, wind)) |>
write.csv("hurricanes.csv", row.names = FALSE)
hurricanes |>
select(c(year, name, wind)) |>
write.csv("hurricanes.csv", row.names = FALSE)
# Load data from hurricanes.csv
hurricanes <- read.csv("hurricanes.csv")
View(hurricanes)
# Rearrange the dataframe in ascending order of year and then within that year, sort from highest wind speed to lowest.
# We can use group_by function
# First find groups of data by year
# We can then apply a function to each group
hurricanes |> group_by(year)
# Rearrange the dataframe in ascending order of year and then within that year, sort from highest wind speed to lowest.
# We can use group_by function
# First find groups of data by year
# We can then apply a function to each group
hurricanes |> arrange(year) |> group_by(year)
# Rearrange the dataframe in ascending order of year and then within that year, sort from highest wind speed to lowest.
# We can use group_by function
# First find groups of data by year
# We can then apply a function to each group
hurricanes |> group_by(year)
hurricanes |> arrange(year) |> group_by(year)
hurricanes |> group_by(year) |> arrange(desc(wind))
hurricanes |> group_by(year) |> arrange(desc(wind)) |> slice_head () # will give us the one storm that had the highest wind speed in each year.
hurricanes |> group_by(year) |> arrange(desc(wind))
hurricanes |> group_by(year) |> arrange(desc(wind)) |> slice_head () # will give us the one storm that had the highest wind speed in each year.
hurricanes |> group_by(year) |> slice_max(order_by = wind)
hurricanes |> group_by(year) |> arrange(desc(wind)) |> slice_head () # will give us the one storm that had the highest wind speed in each year.
# For each year, how many hurricanes occurred for each year?
hurricanes |>
group_by(year) |>
summarize(n()) # n() is a function that finds the number of rows in each group
hurricanes |>
group_by(year) |>
summarize(hurricanes = n()) # n() is a function that finds the number of rows in each group
file.create("students.R")
file.create("shows.R")
students <- read.csv("students.csv")
View(students)
# id_col - which column to use for id
#names_from = which columns to take the new column names from
#values_from = which columns to take the new column values from
students <- pivot_wider(
students,
id_cols = student,
names_from = attribute,
values_from = value
)
students$GPA <- as.numeric(students$GPA)
students
students |>
group_by(major) |>
summarize(meanGPA = mean(GPA))
students <- read.csv("students.csv")
students
# id_col - which column to use for id
#names_from = which columns to take the new column names from
#values_from = which columns to take the new column values from
students <- pivot_wider(
students,
id_cols = student,
names_from = attribute,
values_from = value
)
students
students$GPA <- as.numeric(students$GPA)
students
students |>
group_by(major) |>
summarize(meanGPA = mean(GPA))
shows <- read.csv("shows.csv")
shows
shows <- read.csv("shows.csv")
#Clean up show names to remove extra spaces from front and back and in between the
shows$show <-shows$show |>
str_trim() |>
str_squish() |>
str_to_title()
shows
str_detect(shows$show, "Avatar")
shows$show[str_detect(shows$show, "Avatar")]
# count votes for each show
shows |>
group_by(show) |>
summarize(votes = n()) |>
ungroup() |>
arrange(desc(votes))
shows$show[str_detect(shows$show, "Avatar"),]
shows[str_detect(shows$show, "Avatar"),]
shows[,str_detect(shows$show, "Avatar")]
shows[str_detect(shows$show, "Avatar"),]
file.create("candy.R")
load("candy.RData")
ggplot(
candy,
aes(x = price_percentile, y = sugal_percentile)
) +
geom_jitter()
library("tidyverse")
load("candy.RData")
ggplot(
candy,
aes(x = price_percentile, y = sugal_percentile)
) +
geom_jitter()
ggplot(
candy,
aes(x = price_percentile, y = sugar_percentile)
) +
geom_jitter()
ggplot(
candy,
aes(x = price_percentile, y = sugar_percentile)
) +
geom_jitter() +
labs(
x="Price",
y="Sugal Precentile",
)
ggplot(
candy,
aes(x = price_percentile, y = sugar_percentile)
) +
geom_jitter() +
labs(
x="Price",
y="Sugal Precentile",
"Price and Sugar"
) +
theme_classic()
ggplot(
candy,
aes(x = price_percentile, y = sugar_percentile)
) +
geom_jitter() +
labs(
x="Price",
y="Sugal Precentile",
title = "Price and Sugar"
) +
theme_classic()
ggplot(
candy,
aes(x = price_percentile, y = sugar_percentile)
) +
geom_jitter(
color = "darkorchid"
) +
labs(
x="Price",
y="Sugal Precentile",
title = "Price and Sugar"
) +
theme_classic()
gc()
ls()
gc()
setwd("../stat115/")
